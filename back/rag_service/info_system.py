import asyncio
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Literal, Tuple
from threading import Lock, RLock

from dotenv import load_dotenv
from pydantic import BaseModel, Field

from langchain_groq import ChatGroq
from langgraph.graph import END, StateGraph
from langchain_core.exceptions import OutputParserException
load_dotenv()
from .defense_layers import SandwichDefense, SeparateLLMEvaluation, detect_information_leakage
from .filtering import AdvancedFilteringSystem
from .intent_classifier import IntentClassifier
from .navigation import PathNavigationSystem
from .state import UniversityMEState
from .vector_store import MechanicalEngineeringRAG

logger = logging.getLogger(__name__)

NO_INFORMATION_FALLBACK = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë³´ìœ í•œ ì •ë³´ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
UNSAFE_RESPONSE_MESSAGE = "ì£„ì†¡í•©ë‹ˆë‹¤. ì•ˆì „í•œ ì‘ë‹µì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
UNSUPPORTED_INTENT_MESSAGE = "ìš”ì²­í•˜ì‹  ë‚´ìš©ì€ ì§€ì› ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤. êµìˆ˜/ìˆ˜ì—…/ì„¸ë¯¸ë‚˜ì‹¤ ì •ë³´ë§Œ ì•ˆë‚´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
MALICIOUS_INTENT_MESSAGE = "ì•ˆì „í•˜ì§€ ì•Šì€ ìš”ì²­ìœ¼ë¡œ ê°ì§€ë˜ì–´ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

RESPONSE_POLICY_KEYWORDS = [
    "ì‹œìŠ¤í…œ ì§€ì‹œ",
    "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
    "system prompt",
    "developer message",
    "ë‚´ë¶€ ê·œì¹™",
    "ë¹„ê³µê°œ ì§€ì¹¨",
]

STRUCTURED_OUTPUT_GUIDE = f"""
[Structured Output ê·œì¹™]
- ì‹œìŠ¤í…œì€ RAGStructuredOutput ìŠ¤í‚¤ë§ˆ(ìë™ íŒŒì‹±)ì— ë”°ë¼ ì‘ë‹µí•©ë‹ˆë‹¤.
- final_answer: ê²€ìƒ‰ëœ ì •ë³´ë¡œ ë‹µë³€ì„ ì •ë¦¬í•©ë‹ˆë‹¤. ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ë°˜ë“œì‹œ ë‹¤ìŒ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”: "{NO_INFORMATION_FALLBACK}"
- reasoning_steps: ë‹µë³€ ë„ì¶œ ê³¼ì •ì„ 2~5ë‹¨ê³„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤. ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°ì—ë„ í™•ì¸ ê³¼ì •ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
- retrieved_facts: ì‹ ë¢° ê°€ëŠ¥í•œ ê·¼ê±° ë¬¸ì¥ì„ bullet í˜•ì‹ìœ¼ë¡œ ìµœëŒ€ 5ê°œ ê¸°ë¡í•©ë‹ˆë‹¤. ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
- intentê°€ seminar_recommendationì´ë¼ë©´ ê²€ìƒ‰ëœ ëª¨ë“  ì„¸ë¯¸ë‚˜ì‹¤ í›„ë³´ë¥¼ ë¹„êµÂ·í‰ê°€í•˜ì—¬ ìµœì ì˜ ì„ íƒ ì´ìœ ì™€ í•¨ê»˜ final_answerì™€ retrieved_factsì— ë°˜ì˜í•˜ì„¸ìš”.
- missing_information: ë¶€ì¡±í•˜ê±°ë‚˜ ì¶”ê°€ë¡œ í™•ë³´í•´ì•¼ í•˜ëŠ” ì •ë³´ë¥¼ êµ¬ì²´ì ì¸ í•­ëª© ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. ì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
- needs_navigation: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ìœ„ì¹˜Â·ê²½ë¡œ ì•ˆë‚´ë¥¼ ìš”êµ¬í•œë‹¤ê³  íŒë‹¨ë  ë•Œë§Œ Trueë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
- follow_up_questions: ì‚¬ìš©ìê°€ ì´ì–´ì„œ í™•ì¸í•˜ë©´ ì¢‹ì€ ì§ˆë¬¸ì„ 0~3ê°œ ì œì•ˆí•©ë‹ˆë‹¤.
- destination_room: ê²½ë¡œ ì•ˆë‚´ê°€ í•„ìš”í•œ ê²½ìš° ëª©ì ì§€ ë°© ì´ë¦„/í˜¸ìˆ˜(ì˜ˆ: "301")ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. í•„ìš” ì—†ìœ¼ë©´ nullì„ ìœ ì§€í•©ë‹ˆë‹¤.
- retry_query: ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì›ë˜ì˜ ì§ˆì˜ì˜ ë‚´ìš©ê³¼ ì˜ë„ë¥¼ ìœ ì§€(ê²€ìƒ‰ì´ ë” ì˜ë˜ë„ë¡ ì›ë³¸ ì§ˆì˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•¨)í•˜ë©´ì„œ ë¶€ì¡±í•œ ì •ë³´ë¥¼ ë³´ì¶©í•  ìˆ˜ ìˆëŠ” ì§ˆì˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. í•„ìš” ì—†ìœ¼ë©´ nullì„ ìœ ì§€í•©ë‹ˆë‹¤.
- í—ˆêµ¬ ì •ë³´ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¼ê±°ê°€ ì—†ìœ¼ë©´ final_answerì— ìœ„ì˜ ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ê³  missing_informationì„ ì±„ì›Œì£¼ì„¸ìš”.
"""
# - follow_up_questions: ì‚¬ìš©ìê°€ ì´ì–´ì„œ í™•ì¸í•˜ë©´ ì¢‹ì€ ì§ˆë¬¸ì„ 0~3ê°œ ì œì•ˆí•©ë‹ˆë‹¤.

class RAGStructuredOutput(BaseModel):
    final_answer: str = Field(..., description="ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ìµœì¢… ë‹µë³€")
    reasoning_steps: List[str] = Field(default_factory=list, description="ë‹µë³€ì„ ë„ì¶œí•œ í•µì‹¬ ë‹¨ê³„")
    retrieved_facts: List[str] = Field(
        default_factory=list, description="ì¶œì²˜ ë¬¸ì„œì—ì„œ í™•ì¸í•œ ê·¼ê±° ë¬¸ì¥ ë˜ëŠ” ìš”ì•½"
    )
    needs_navigation: bool = Field(False, description="ì•ˆë‚´ ì§€ë„ê°€ í•„ìš”í•œ ê²½ìš° True")
    missing_information: List[str] = Field(
        default_factory=list, description="ë‹µë³€ì— í•„ìš”í•œë° í™•ë³´ë˜ì§€ ì•Šì€ ì •ë³´"
    )
    # follow_up_questions: List[str] = Field(
    #     default_factory=list, description="ì‚¬ìš©ìì—ê²Œ ì œì•ˆí•  í›„ì† ì§ˆë¬¸ ë˜ëŠ” í™•ì¸ ì‚¬í•­"
    # )
    destination_room: Optional[str] = Field(
        default=None,
        description="ê²½ë¡œ ì•ˆë‚´ê°€ í•„ìš”í•œ ê²½ìš° ëª©ì ì§€ ë°© ì´ë¦„ ë˜ëŠ” í˜¸ìˆ˜",
    )
    retry_query: Optional[str] = Field(
        default=None,
        description="ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì¶”ê°€ ê²€ìƒ‰í•  ì¿¼ë¦¬",
    )


class GuardrailVerdict(BaseModel):
    is_safe: bool = Field(default=True, description="ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€")
    reason: str = Field(default="ok", description="íŒë‹¨ ê·¼ê±° ìš”ì•½")
    category: Literal[
        "ok",
        "system_manipulation",
        "personal_information",
        "academic_misconduct",
        "abuse",
        "other",
    ] = Field(default="ok", description="ì°¨ë‹¨ ì¹´í…Œê³ ë¦¬")


class UniversityMEInfoSystem:
    def __init__(
        self,
        data_path: Optional[Path] = None,
        enable_intent_rewrite: bool = False,
        use_guardrail: bool = False,
    ):
        default_data = Path(__file__).resolve().parents[0] / "n7_professor_lectures_seminar.json"
        self.data_path = data_path or default_data
        self.enable_intent_rewrite = enable_intent_rewrite
        self.use_guardrail = use_guardrail

        self.initialization_error: Optional[str] = None
        self.rag_system = MechanicalEngineeringRAG(auto_initialize=False)
        self._rag_lock: Lock = Lock()
        self._rag_initialized = False

        self.intent_classifier = IntentClassifier(enable_rewrite=self.enable_intent_rewrite)
        self._navigation_system: Optional[PathNavigationSystem] = None
        self._navigation_lock: Lock = Lock()

        self.filtering_system = AdvancedFilteringSystem()
        self.sandwich_defense = SandwichDefense()
        self.llm_evaluation = SeparateLLMEvaluation()

        self._llm_lock: RLock = RLock()
        self._main_llm: Optional[ChatGroq] = None
        self._structured_main_llm = None
        self._intent_guard: Optional[ChatGroq] = None
        self._intent_guard_structured = None

        self.max_question_sentences = 5
        self.max_question_tokens = 900
        self.workflow = self._create_workflow()

    @property
    def navigation_system(self) -> PathNavigationSystem:
        if self._navigation_system is None:
            with self._navigation_lock:
                if self._navigation_system is None:
                    self._navigation_system = PathNavigationSystem()
        return self._navigation_system

    @property
    def main_llm(self) -> ChatGroq:
        if self._main_llm is None:
            with self._llm_lock:
                if self._main_llm is None:
                    self._main_llm = ChatGroq(
                        model_name="openai/gpt-oss-120b",
                        temperature=0.2,
                    )
        return self._main_llm

    @property
    def structured_main_llm(self):
        if self._structured_main_llm is None:
            with self._llm_lock:
                if self._structured_main_llm is None:
                    self._structured_main_llm = self.main_llm.with_structured_output(RAGStructuredOutput)
        return self._structured_main_llm

    @property
    def intent_guard(self) -> ChatGroq:
        if self._intent_guard is None:
            with self._llm_lock:
                if self._intent_guard is None:
                    self._intent_guard = ChatGroq(
                        model_name="llama-3.1-8b-instant",
                        temperature=0,
                    )
        return self._intent_guard

    @property
    def intent_guard_structured(self):
        if self._intent_guard_structured is None:
            with self._llm_lock:
                if self._intent_guard_structured is None:
                    self._intent_guard_structured = self.intent_guard.with_structured_output(GuardrailVerdict)
        return self._intent_guard_structured

    def _initialize_rag(self) -> None:
        if self._rag_initialized:
            return
        with self._rag_lock:
            if self._rag_initialized:
                return

            try:
                existing_records = self.rag_system.db_manager.count()
            except Exception:
                existing_records = 0

            try:
                if existing_records == 0:
                    if not self.data_path.exists():
                        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_path}")
                    self.rag_system.initialize_from_json(self.data_path, rebuild=False)
                else:
                    self.rag_system.refresh_documents()
            except Exception as exc:
                self.initialization_error = str(exc)
                logger.exception("RAG ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                raise
            else:
                self.initialization_error = None
                self._rag_initialized = True
                try:
                    doc_count = self.rag_system.db_manager.count()
                except Exception:
                    doc_count = -1
                if doc_count >= 0:
                    logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - %dê°œ ë¬¸ì„œ ë¡œë“œ", doc_count)
                else:
                    logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def ensure_rag_ready(self) -> None:
        if self._rag_initialized:
            return
        await asyncio.to_thread(self._initialize_rag)

    def _ensure_llms_ready(self) -> None:
        _ = self.structured_main_llm
        _ = self.intent_guard_structured

    async def warm_up(self, *, include_navigation: bool = False) -> None:
        try:
            await self.ensure_rag_ready()
        except Exception:
            # ì˜¤ë¥˜ëŠ” initialization_errorì— ê¸°ë¡ë˜ê³  ë¡œê·¸ë¡œ ë‚¨ìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œ
            pass
        else:
            await asyncio.to_thread(self.rag_system.db_manager.ensure_embeddings_ready)

        await asyncio.to_thread(self._ensure_llms_ready)

        if include_navigation:
            await asyncio.to_thread(lambda: self.navigation_system)

    def _preprocess_query(self, user_query: str) -> Dict:
        normalized = user_query.strip()
        if not normalized:
            return {"is_valid": False, "message": "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ê³„ê³µí•™ê³¼ ê´€ë ¨ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}

        sentences = [sentence.strip() for sentence in re.split(r"(?<=[.!?ï¼Ÿ])\s+", normalized) if sentence.strip()]
        warnings: List[str] = []

        if len(sentences) > self.max_question_sentences:
            normalized = " ".join(sentences[: self.max_question_sentences])
            warnings.append(f"ì§ˆë¬¸ì´ ê¸¸ì–´ ì²˜ìŒ {self.max_question_sentences}ë¬¸ì¥ë§Œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")

        tokens = normalized.split()
        if len(tokens) > self.max_question_tokens:
            normalized = " ".join(tokens[: self.max_question_tokens])
            warnings.append("ì§ˆë¬¸ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì¼ë¶€ë§Œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")

        return {
            "is_valid": True,
            "normalized": normalized,
            "warnings": warnings,
        }

    def _apply_structured_guidelines(self, prompt: str) -> str:
        prompt = prompt.rstrip()
        return f"{prompt}\n\n{STRUCTURED_OUTPUT_GUIDE}\n"

    def _guardrail_screen(self, query: str) -> Dict:
        prompt = f"""
ì—­í• : ê¸°ê³„ê³µí•™ê³¼ ì•ˆë‚´ ì‹œìŠ¤í…œ ë³´ì•ˆ ê°ì‹œì
ì‚¬ìš©ì ìš”ì²­ì„ ê²€í† í•˜ì—¬ ì•ˆì „í•œì§€ íŒë‹¨í•˜ì„¸ìš”.

ìš”ì²­: \"\"\"{query}\"\"\"

JSONìœ¼ë¡œë§Œ ë‹µë³€:
{{
  "is_safe": true/false,
  "reason": "íŒë‹¨ ê·¼ê±°",
  "category": "ok|system_manipulation|personal_information|academic_misconduct|abuse|other"
}}
"""
        try:
            verdict: GuardrailVerdict = self.intent_guard_structured.invoke(prompt)
            result = verdict.dict()
        except Exception:
            result = {"is_safe": True, "reason": "guard_fallback", "category": "ok"}

        return {
            "is_safe": bool(result.get("is_safe", True)),
            "reason": result.get("reason", "guard_fallback"),
            "category": result.get("category", "ok"),
        }

    def _build_rejection(self, message: str, blocked_by: Optional[List[str]] = None) -> Dict:
        return {
            "final_output": message,
            "filter_results": {"is_safe": False, "blocked_by": blocked_by or [], "confidence": 0.95},
            "detected_intent": "blocked",
            "intent_confidence": 0.0,
            "retrieved_documents": [],
            "llm_response": "",
            "needs_navigation": False,
            "navigation_info": {},
            "processing_log": ["Query rejected before processing."],
        }

    def _build_initial_state(
        self,
        question: str,
        question_index: int,
        total_questions: int,
        preprocessing_notes: List[str],
    ) -> UniversityMEState:
        return UniversityMEState(
            user_query=question,
            detected_intent="",
            intent_confidence=0.0,
            retrieved_documents=[],
            backup_documents=[],
            llm_response="",
            final_output="",
            filter_checks={},
            filter_results={},
            llm_evaluation={},
            structured_output={},
            needs_navigation=False,
            navigation_info={},
            processing_log=[f"ì§ˆë¬¸ {question_index}/{total_questions} ì²˜ë¦¬ ì‹œì‘: {question}"],
            question_index=question_index,
            total_questions=total_questions,
            preprocessing_notes=list(preprocessing_notes),
            sanitized_query="",
            effective_query=question,
            rewritten_query="",
            rewrite_attempted=not self.enable_intent_rewrite,
            llm_prompt_query=question,
            retry_query="",
            llm_retry_used=False,
            intent_is_malicious=False,
            abort_message="",
            needs_retry=False,
            retry_reason="",
        )

    def _retrieve_documents_for_intent(
        self,
        intent: str,
        query: str,
        *,
        top_k: int = 10,
        preview_k: int = 5,
    ) -> Dict[str, List[str]]:
        if intent == "seminar_recommendation":
            docs = self.rag_system.search_all_seminar_rooms(query)
            preview_docs = docs
            backup_docs: List[Any] = []
        else:
            docs = self.rag_system.search(query, top_k=top_k)
            preview_docs = docs[:preview_k]
            backup_docs = docs[preview_k:]
        return {
            "preview": [doc.page_content for doc in preview_docs],
            "backup": [doc.page_content for doc in backup_docs],
            "total": len(docs),
            "preview_count": len(preview_docs),
        }

    def _create_workflow(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""

        def preprocess_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Preprocessing user query...")
            analysis = self._preprocess_query(state["user_query"])

            if not analysis["is_valid"]:
                state["abort_message"] = analysis["message"]
                state["filter_results"] = {
                    "is_safe": False,
                    "blocked_by": ["pre_filter"],
                    "confidence": 0.95,
                }
                state.setdefault("preprocessing_notes", [])
                state["processing_log"].append(f"Preprocessing rejected query: {analysis['message']}")
                return state

            normalized = analysis.get("normalized", state["user_query"])
            state["sanitized_query"] = normalized
            state["effective_query"] = normalized
            state["llm_prompt_query"] = normalized

            notes = list(analysis.get("warnings") or [])
            if notes:
                state.setdefault("preprocessing_notes", [])
                state["preprocessing_notes"].extend(notes)

            state["processing_log"].append("Preprocessing completed.")
            return state

        def guardrail_node(state: UniversityMEState) -> UniversityMEState:

            state["processing_log"].append("Running guardrail checks...")
            query = state.get("sanitized_query") or state["user_query"]
            verdict = self._guardrail_screen(query)
            state.setdefault("filter_checks", {})["guardrail"] = verdict

            reason = verdict.get("reason")
            if reason and reason not in {"ok", "guard_fallback"}:
                state.setdefault("preprocessing_notes", [])
                state["preprocessing_notes"].append(f"ì‚¬ì „ ë³´ì•ˆ ì ê²€ ê²°ê³¼: {reason}")

            if not verdict.get("is_safe", True):
                state["abort_message"] = (
                    "ì£„ì†¡í•©ë‹ˆë‹¤. ë³´ì•ˆ ì •ì±…ì— ë”°ë¼ í•´ë‹¹ ì§ˆë¬¸ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ê³„ê³µí•™ê³¼ ê´€ë ¨ëœ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
                )
                state["filter_results"] = {
                    "is_safe": False,
                    "blocked_by": [verdict.get("category", "guardrail")],
                    "confidence": 0.95,
                }
                state["processing_log"].append("Guardrail rejected the query.")
            else:
                state.setdefault("filter_results", {"is_safe": True, "blocked_by": [], "confidence": 1.0})

            return state

        def input_filtering_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append(
                f"Starting input filtering (question {state['question_index']}/{state['total_questions']})..."
            )
            for note in state.get("preprocessing_notes", []):
                state["processing_log"].append(f"Preprocess note: {note}")

            sanitized = self.filtering_system.sanitize_text(state.get("sanitized_query", state["user_query"]))
            state["sanitized_query"] = sanitized
            state["filter_checks"] = {}
            state["filter_results"] = {
                "is_safe": True,
                "blocked_by": [],
                "confidence": 1.0,
                "sanitized_text": sanitized,
                "warnings": [],
            }
            return state

        def basic_filter_node(state: UniversityMEState) -> UniversityMEState:
            result = self.filtering_system.basic_keyword_filter(state.get("sanitized_query", state["user_query"]))
            state.setdefault("filter_checks", {})["basic"] = result
            if not result.get("is_safe", True):
                state["processing_log"].append(f"Basic filter flagged issue: {result.get('reason')}")
            return state

        def pattern_filter_node(state: UniversityMEState) -> UniversityMEState:
            result = self.filtering_system.pattern_filter(state.get("sanitized_query", state["user_query"]))
            state.setdefault("filter_checks", {})["pattern"] = result
            if not result.get("is_safe", True):
                state["processing_log"].append(f"Pattern filter flagged issue: {result.get('reason')}")
            return state

        def semantic_filter_node(state: UniversityMEState) -> UniversityMEState:
            result = self.filtering_system.semantic_filter(state.get("sanitized_query", state["user_query"]))
            state.setdefault("filter_checks", {})["semantic"] = result
            if not result.get("is_safe", True):
                state["processing_log"].append(f"Semantic filter flagged issue: {result.get('reason')}")
            return state

        def filter_merge_node(state: UniversityMEState) -> UniversityMEState:
            checks = state.get("filter_checks", {})
            required = {"basic", "pattern", "semantic"}
            if not required.issubset(checks):
                return state

            merged = self.filtering_system.combine_results(state.get("sanitized_query", state["user_query"]), checks)
            state["filter_results"] = merged
            state["processing_log"].append(
                "Filter results combined: " + ("safe" if merged["is_safe"] else "blocked")
            )
            if not merged["is_safe"]:
                state["abort_message"] = self._get_rejection_message(merged["blocked_by"])
                state["processing_log"].append(
                    f"Filtering blocked query: {merged['blocked_by']} -> {state['abort_message']}"
                )
            return state

        def intent_classification_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Classifying user intent...")
            classification = self.intent_classifier.classify_intent(
                state.get("sanitized_query", state["user_query"])
            )

            state["detected_intent"] = classification["intent"]
            state["intent_confidence"] = classification["confidence"]

            if self.enable_intent_rewrite:
                rewritten_query = (
                    classification.get("rewritten_query") or state.get("sanitized_query", state["user_query"])
                ).strip()
                state["rewritten_query"] = rewritten_query or state.get("sanitized_query", state["user_query"])
                state["rewrite_attempted"] = False
            else:
                state["rewritten_query"] = ""
                state["rewrite_attempted"] = True

            state["effective_query"] = state.get("sanitized_query", state["user_query"])
            state["llm_prompt_query"] = state["effective_query"]
            state["retry_query"] = ""
            state["llm_retry_used"] = False
            state["intent_is_malicious"] = bool(classification.get("is_malicious", False))
            state["processing_log"].append(
                f"Intent: {classification['intent']} (confidence: {classification['confidence']:.2f})"
            )

            allowed_intents = {"professor_info", "class_info", "seminar_recommendation", "multiple"}
            if classification["intent"] not in allowed_intents:
                state["abort_message"] = UNSUPPORTED_INTENT_MESSAGE
            if state["intent_is_malicious"] or classification.get("risk_level") in {"medium", "high"}:
                state["abort_message"] = MALICIOUS_INTENT_MESSAGE

            return state

        def retry_router_node(state: UniversityMEState) -> UniversityMEState:
            mode = state.get("retry_mode", "")
            if not mode:
                return state

            if mode == "llm_query":
                retry_query = state.get("retry_query", "").strip()
                state["processing_log"].append(f"Retry router applied LLM query: '{retry_query}'")
                state["effective_query"] = retry_query
                state["llm_prompt_query"] = retry_query
                state["retry_mode"] = ""
                state["needs_retry"] = True
                return state

            if mode == "intent_query":
                rewritten_query = state.get("rewritten_query", "").strip()
                state["processing_log"].append(f"Retry router applied intent rewrite: '{rewritten_query}'")
                state["effective_query"] = rewritten_query
                state["llm_prompt_query"] = rewritten_query
                state["retry_mode"] = ""
                state["needs_retry"] = True
                return state

            state["retry_mode"] = ""
            return state

        def rag_retrieval_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Retrieving relevant documents...")

            intent = state["detected_intent"]
            query = state.get("effective_query", state["user_query"])

            retrieval = self._retrieve_documents_for_intent(intent, query)

            state["retrieved_documents"] = retrieval["preview"]
            state["backup_documents"] = retrieval["backup"]
            state["llm_prompt_query"] = query
            state["processing_log"].append(
                f"Retrieved {retrieval['total']} documents (primary {retrieval['preview_count']} used) for query '{query}'."
            )

            return state

        def _build_llm_prompt(query: str, context: str) -> str:
            base_prompt = self.sandwich_defense.create_sandwich_prompt(query, context)
            return self._apply_structured_guidelines(base_prompt)

        def llm_generation_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Generating LLM response...")
            state["needs_retry"] = False
            state["retry_reason"] = ""
            state["abort_message"] = ""
            state["retry_mode"] = ""

            prompt_query = state.get("llm_prompt_query", state["user_query"])
            prompt = _build_llm_prompt(prompt_query, "\n".join(state["retrieved_documents"]))
            state["processing_log"].append("Using default multi-layer defense prompt.")

            try:
                structured = self.structured_main_llm.invoke(prompt)
                print("Structured LLM output:", structured)  # --- IGNORE ---
            except OutputParserException as exc:
                state["processing_log"].append(f"Structured LLM output failed: {exc}")
                fallback_text = ""
                try:
                    raw_response = self.main_llm.invoke(prompt)
                    fallback_text = getattr(raw_response, "content", str(raw_response)).strip()
                    state["processing_log"].append("Fallback raw LLM response generated instead.")
                except Exception as gen_exc:
                    state["processing_log"].append(f"Fallback LLM call also failed: {gen_exc}")
                final_answer = fallback_text or NO_INFORMATION_FALLBACK
                structured = RAGStructuredOutput(
                    final_answer=final_answer,
                    reasoning_steps=[],
                    retrieved_facts=[],
                    needs_navigation=False,
                    missing_information=[],
                    destination_room=None,
                    retry_query=None,
                )
            except Exception as exc:
                state["processing_log"].append(f"Unexpected structured LLM error: {exc}")
                raise
            state["structured_output"] = structured.dict()
            state["llm_response"] = structured.final_answer.strip()
            if structured.reasoning_steps:
                state["processing_log"].append(
                    f"Structured reasoning steps provided: {len(structured.reasoning_steps)} ë‹¨ê³„"
                )

            missing_info = list(structured.missing_information or [])
            
            retry_query = (structured.retry_query or "").strip()
            state["retry_query"] = retry_query

            if missing_info:
                print("Missing information detected:", missing_info)
                state["processing_log"].append(
                    "Structured output reports missing information: " + ", ".join(missing_info)
                )

                if state.get("backup_documents"):
                    additional_docs = state["backup_documents"][:5]
                    state["retrieved_documents"].extend(additional_docs)
                    state["backup_documents"] = []
                    state["processing_log"].append(
                        f"ì¶”ê°€ ë¬¸ì„œ {len(additional_docs)}ê°œë¥¼ í™•ë³´í•˜ì—¬ ì¬ìƒì„±ì„ ì¤€ë¹„í•©ë‹ˆë‹¤."
                    )
                    state["needs_retry"] = True
                    state["retry_mode"] = "add_docs"
                    state["retry_reason"] = "ì¶”ê°€ ë¬¸ì„œë¡œ ì¬ìƒì„± ì¬ì‹œë„"
                    return state

                if (
                    retry_query
                    and not state.get("llm_retry_used", False)
                    and retry_query.lower() != state.get("effective_query", "").lower()
                ):
                    state["processing_log"].append(f"Retrying with LLM suggested query: '{retry_query}'")
                    state["retry_query"] = retry_query
                    state["llm_retry_used"] = True
                    state["needs_retry"] = True
                    state["retry_reason"] = "LLMì´ ì œì•ˆí•œ ì¬ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„"
                    state["retry_mode"] = "llm_query"
                    return state

                rewritten_query = state.get("rewritten_query", "").strip()
                rewrite_available = (
                    self.enable_intent_rewrite
                    and bool(rewritten_query)
                    and rewritten_query.lower() != state.get("effective_query", "").lower()
                    and not state.get("rewrite_attempted", False)
                )

                if rewrite_available:
                    state["processing_log"].append(f"Retrying with rewritten query: '{rewritten_query}'")
                    state["rewrite_attempted"] = True
                    state["needs_retry"] = True
                    state["retry_reason"] = "ì¬ì‘ì„±ëœ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰ ì¬ì‹œë„"
                    state["retry_mode"] = "intent_query"
                    return state

                state["processing_log"].append("ì¶”ê°€ ì •ë³´ë¥¼ í™•ë³´í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì•ˆë‚´ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                state["abort_message"] = NO_INFORMATION_FALLBACK
            if structured.needs_navigation or structured.destination_room:
                state["needs_navigation"] = True
                state["processing_log"].append("Structured output requested navigation assistance.")
            destination_room = structured.destination_room
            if destination_room and destination_room.strip():
                state["processing_log"].append(f"Structured output destination detected: {destination_room}")
                state.setdefault("navigation_info", {})
                state["navigation_info"]["destination_room"] = destination_room.strip()
            return state

        def policy_regex_check_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Running policy regex checks on response...")
            response_text = state.get("llm_response", "") or ""

            filter_checks = state.setdefault("filter_checks", {})
            leak_result = detect_information_leakage(response_text)
            filter_checks["policy_regex_leakage"] = leak_result

            blocked = False
            blocked_reasons: List[str] = []

            if leak_result.get("has_leakage"):
                blocked = True
                blocked_reasons.append("policy_regex_leakage")

            keyword_matches = [kw for kw in RESPONSE_POLICY_KEYWORDS if kw.lower() in response_text.lower()]
            filter_checks["policy_keyword_scan"] = {"matches": keyword_matches}
            if keyword_matches:
                blocked = True
                blocked_reasons.append("policy_keyword_scan")

            if blocked:
                state["processing_log"].append(
                    "Policy regex checks flagged response issues: " + ", ".join(blocked_reasons)
                )
                state["abort_message"] = UNSAFE_RESPONSE_MESSAGE
                filter_results = state.setdefault("filter_results", {"is_safe": True, "blocked_by": []})
                filter_results["is_safe"] = False
                filter_results.setdefault("blocked_by", [])
                blocked_by = set(filter_results.get("blocked_by") or [])
                blocked_by.update(blocked_reasons)
                filter_results["blocked_by"] = list(blocked_by)
            else:
                state["processing_log"].append("Policy regex checks passed.")
            print("regex blocked: ", blocked)  # --- IGNORE ---
            return state

        def llm_evaluation_dispatch_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Dispatching LLM evaluations...")
            return state

        async def llm_security_eval_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Security evaluation in progress...")
            result = await self.llm_evaluation.security_evaluation(state["user_query"], state["llm_response"])
            parts = state.setdefault("llm_evaluation", {})
            parts["security"] = result
            return state

        async def llm_content_eval_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Content evaluation in progress...")
            context = "\n".join(state["retrieved_documents"])
            result = await self.llm_evaluation.content_evaluation(state["user_query"], state["llm_response"], context)
            parts = state.setdefault("llm_evaluation", {})
            parts["content"] = result
            return state

        def llm_evaluation_merge_node(state: UniversityMEState) -> UniversityMEState:
            parts = state.get("llm_evaluation", {})
            required_keys = {"security", "content"}
            if not required_keys.issubset(parts):
                return state
            security_result = parts["security"]
            content_result = parts["content"]
            
            combined = self.llm_evaluation.combine_evaluations([security_result, content_result])
            state["llm_evaluation"] = combined
            state["processing_log"].append("LLM evaluation merged across security/content checks.")
            action = combined.get("recommended_action", "allow")
            if action not in {"allow", "noop"} or not combined.get("is_safe", True):
                state["abort_message"] = UNSAFE_RESPONSE_MESSAGE
            return state

        def navigation_check_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Checking navigation requirements...")
            structured_output = state.get("structured_output", {}) or {}
            destination_hint = (structured_output.get("destination_room") or "").strip()
            structured_hint = bool(structured_output.get("needs_navigation") or destination_hint)
            if destination_hint:
                state.setdefault("navigation_info", {})
                state["navigation_info"]["destination_room"] = destination_hint
            should_offer = structured_hint or self.navigation_system.should_offer_navigation(
                state["detected_intent"],
                state.get("sanitized_query", state["user_query"]),
                state["llm_response"],
            )
            state["needs_navigation"] = should_offer
            if should_offer:
                state["processing_log"].append("Navigation assistance offered")
            return state

        def final_response_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Generating final response...")

            abort_message = (state.get("abort_message") or "").strip()
            if abort_message:
                state["needs_navigation"] = False
                state["final_output"] = abort_message
                state["processing_log"].append("Final response aborted due to policy checks.")
                return state

            structured = state.get("structured_output", {})
            final_response = state.get("llm_response", "").strip() or NO_INFORMATION_FALLBACK

            supplemental_sections: List[str] = []

            missing_info = structured.get("missing_information") or []
            if missing_info:
                formatted = "\n".join(f"- {item}" for item in missing_info)
                supplemental_sections.append(f"ğŸ” ì¶”ê°€ í™•ì¸ í•„ìš”\n{formatted}")

            # follow_ups = structured.get("follow_up_questions") or []
            # if follow_ups:
            #     formatted = "\n".join(f"- {item}" for item in follow_ups[:5])
            #     supplemental_sections.append(f"ì œì•ˆ ì§ˆë¬¸\n{formatted}")

            retrieved_facts = structured.get("retrieved_facts") or []
            if retrieved_facts:
                formatted = "\n".join(f"- {fact}" for fact in retrieved_facts[:5])
                supplemental_sections.append(f"ğŸ“š ê·¼ê±° ë©”ëª¨\n{formatted}")

            destination_room = (structured.get("destination_room") or "").strip()
            if destination_room:
                supplemental_sections.append(f"ğŸ—‚ï¸ ëª©ì ì§€: {destination_room}")

            nav_info = (state.get("navigation_info") or {}).copy()
            if nav_info.get("success"):
                map_lines = []
                message = (nav_info.get("message") or "").strip()
                if message:
                    map_lines.append(message)
                map_path = (nav_info.get("map_path") or "").strip()
                if map_path:
                    map_lines.append(f"ì§€ë„ íŒŒì¼: {map_path}")
                if map_lines:
                    supplemental_sections.append("ğŸ—ºï¸ ê²½ë¡œ ì•ˆë‚´\n" + "\n".join(map_lines))
            elif nav_info:
                failure_message = (nav_info.get("message") or "ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.").strip()
                supplemental_sections.append(f"âŒ ì§€ë„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {failure_message}")

            if supplemental_sections:
                final_response = f"{final_response}\n\n" + "\n\n".join(supplemental_sections)

            if state.get("needs_navigation") and not nav_info.get("success"):
                final_response += "\n\nğŸ“ ìœ„ì¹˜ ì°¾ê¸°ì— ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ 'ê²½ë¡œ ì•ˆë‚´í•´ì£¼ì„¸ìš”'ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”!"

            state["final_output"] = final_response
            state["processing_log"].append("Final response generated")
            return state

        def navigation_generation_node(state: UniversityMEState) -> UniversityMEState:
            state["processing_log"].append("Generating navigation map...")
            destination = (state.get("navigation_info", {}) or {}).get("destination_room")

            if destination:
                nav_result = self.navigation_system.generate_navigation_map(destination)
                nav_result["destination_room"] = destination
                state["navigation_info"] = nav_result
                if nav_result["success"]:
                    state["processing_log"].append("Navigation map generated successfully.")
                else:
                    state["processing_log"].append(
                        f"Navigation map generation failed: {nav_result.get('message', 'unknown reason')}."
                    )
            else:
                state["processing_log"].append("Navigation destination not provided; skipping map generation.")

            return state

        def should_continue_after_filter(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            return "intent_classification"

        def should_continue_after_preprocess(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            return "guardrail_check" if self.use_guardrail else "input_filtering"

        def should_continue_after_guardrail(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            return "input_filtering"

        def should_continue_after_intent(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            return "rag_retrieval"

        def should_retry_after_generation(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            if state.get("needs_retry"):
                if state.get("retry_mode") == "add_docs":
                    return "llm_generation"
                return "retry_router"
            return "policy_regex_check"

        def should_proceed_after_policy_regex(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            return "llm_evaluation_dispatch"

        def should_proceed_after_evaluation(state: UniversityMEState) -> str:
            if state.get("abort_message"):
                return "final_response"
            return "navigation_check"

        def should_generate_navigation(state: UniversityMEState) -> str:
            destination_present = bool((state.get("navigation_info", {}) or {}).get("destination_room"))
            if state.get("abort_message"):
                return "final_response"
            if state.get("needs_navigation") and destination_present:
                return "navigation_generation"
            return "final_response"

        workflow = StateGraph(UniversityMEState)

        workflow.add_node("query_preprocess", preprocess_node)
        if self.use_guardrail:
            workflow.add_node("guardrail_check", guardrail_node)
        workflow.add_node("input_filtering", input_filtering_node)
        workflow.add_node("basic_filter", basic_filter_node)
        workflow.add_node("pattern_filter", pattern_filter_node)
        workflow.add_node("semantic_filter", semantic_filter_node)
        workflow.add_node("filter_merge", filter_merge_node)
        workflow.add_node("intent_classification", intent_classification_node)
        workflow.add_node("retry_router", retry_router_node)
        workflow.add_node("rag_retrieval", rag_retrieval_node)
        workflow.add_node("llm_generation", llm_generation_node)
        workflow.add_node("policy_regex_check", policy_regex_check_node)
        workflow.add_node("llm_evaluation_dispatch", llm_evaluation_dispatch_node)
        workflow.add_node("llm_security_eval", llm_security_eval_node)
        workflow.add_node("llm_content_eval", llm_content_eval_node)
        workflow.add_node("llm_evaluation_merge", llm_evaluation_merge_node)
        workflow.add_node("navigation_check", navigation_check_node)
        workflow.add_node("navigation_generation", navigation_generation_node)
        workflow.add_node("final_response", final_response_node)

        workflow.set_entry_point("query_preprocess")
        if self.use_guardrail:
            workflow.add_conditional_edges(
                "query_preprocess",
                should_continue_after_preprocess,
                {
                    "guardrail_check": "guardrail_check",
                    "final_response": "final_response",
                },
            )
            workflow.add_conditional_edges(
                "guardrail_check",
                should_continue_after_guardrail,
                {
                    "input_filtering": "input_filtering",
                    "final_response": "final_response",
                },
            )
        else:
            workflow.add_conditional_edges(
                "query_preprocess",
                should_continue_after_preprocess,
                {
                    "input_filtering": "input_filtering",
                    "final_response": "final_response",
                },
            )
        workflow.add_edge("input_filtering", "basic_filter")
        workflow.add_edge("input_filtering", "pattern_filter")
        workflow.add_edge("input_filtering", "semantic_filter")
        workflow.add_edge("basic_filter", "filter_merge")
        workflow.add_edge("pattern_filter", "filter_merge")
        workflow.add_edge("semantic_filter", "filter_merge")
        workflow.add_conditional_edges(
            "filter_merge",
            should_continue_after_filter,
            {
                "intent_classification": "intent_classification",
                "final_response": "final_response",
            },
        )
        workflow.add_conditional_edges(
            "intent_classification",
            should_continue_after_intent,
            {
                "rag_retrieval": "rag_retrieval",
                "final_response": "final_response",
            },
        )
        workflow.add_edge("retry_router", "rag_retrieval")
        workflow.add_edge("rag_retrieval", "llm_generation")
        workflow.add_conditional_edges(
            "llm_generation",
            should_retry_after_generation,
            {
                "retry_router": "retry_router",
                "llm_generation": "llm_generation",
                "policy_regex_check": "policy_regex_check",
                "final_response": "final_response",
            },
        )
        workflow.add_conditional_edges(
            "policy_regex_check",
            should_proceed_after_policy_regex,
            {
                "llm_evaluation_dispatch": "llm_evaluation_dispatch",
                "final_response": "final_response",
            },
        )
        workflow.add_edge("llm_evaluation_dispatch", "llm_security_eval")
        workflow.add_edge("llm_evaluation_dispatch", "llm_content_eval")
        workflow.add_edge("llm_content_eval", "llm_evaluation_merge")
        workflow.add_edge("llm_security_eval", "llm_evaluation_merge")
        workflow.add_conditional_edges(
            "llm_evaluation_merge",
            should_proceed_after_evaluation,
            {
                "navigation_check": "navigation_check",
                "final_response": "final_response",
            },
        )
        workflow.add_conditional_edges(
            "navigation_check",
            should_generate_navigation,
            {"navigation_generation": "navigation_generation", "final_response": "final_response"},
        )
        workflow.add_edge("navigation_generation", "final_response")
        workflow.add_edge("final_response", END)

        return workflow.compile()

    def _get_rejection_message(self, blocked_by: List[str]) -> str:
        if "basic_filter" in blocked_by:
            return "ë¶€ì ì ˆí•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ìš”ì²­ì…ë‹ˆë‹¤. ê¸°ê³„ê³µí•™ê³¼ ê´€ë ¨ ì§ˆë¬¸ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        if "pattern_filter" in blocked_by:
            return "ì‹œìŠ¤í…œ ë³´ì•ˆìƒ ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ìš”ì²­ì…ë‹ˆë‹¤."
        if "semantic_filter" in blocked_by:
            return "ê¸°ê³„ê³µí•™ê³¼ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. êµìˆ˜, ìˆ˜ì—…, ì„¸ë¯¸ë‚˜ì‹¤ ì •ë³´ë§Œ ì•ˆë‚´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        return "ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì ˆí•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."

    async def process_query(self, user_query: str) -> Dict:
        if not self._rag_initialized or self.initialization_error:
            try:
                await self.ensure_rag_ready()
            except Exception:
                logger.warning("RAG ì´ˆê¸°í™” ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. initialization_error=%s", self.initialization_error)

        if self.initialization_error:
            return self._build_rejection(
                f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {self.initialization_error}",
                blocked_by=["rag_initialization"],
            )

        question = (user_query or "").strip()
        initial_state = self._build_initial_state(
            question,
            question_index=1,
            total_questions=1,
            preprocessing_notes=[],
        )
        result_state = await self.workflow.ainvoke(initial_state)
        return result_state
